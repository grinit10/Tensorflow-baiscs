{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-04 21:39:26.697902: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customCallback(tf.keras.callbacks.Callback):\n",
    "    loss = 0\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('loss') - self.loss == 0):\n",
    "            self.model.stop_training = True\n",
    "        self.loss = logs.get('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = training_images.reshape(60000,28,28,1)\n",
    "test_images = test_images.reshape(10000,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-04 21:39:28.277395: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-07-04 21:39:28.330771: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-04 21:39:28.331041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce RTX 3080 computeCapability: 8.6\n",
      "coreClock: 1.8GHz coreCount: 68 deviceMemorySize: 9.75GiB deviceMemoryBandwidth: 707.88GiB/s\n",
      "2021-07-04 21:39:28.331059: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-04 21:39:28.340361: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-07-04 21:39:28.340391: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-07-04 21:39:28.344658: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-07-04 21:39:28.346923: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-07-04 21:39:28.349316: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-07-04 21:39:28.351926: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-07-04 21:39:28.352658: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-07-04 21:39:28.352719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-04 21:39:28.353040: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-04 21:39:28.353568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-07-04 21:39:28.353819: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-07-04 21:39:28.354162: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-04 21:39:28.354447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce RTX 3080 computeCapability: 8.6\n",
      "coreClock: 1.8GHz coreCount: 68 deviceMemorySize: 9.75GiB deviceMemoryBandwidth: 707.88GiB/s\n",
      "2021-07-04 21:39:28.354492: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-04 21:39:28.354796: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-04 21:39:28.355065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-07-04 21:39:28.355339: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-04 21:39:28.820635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-07-04 21:39:28.820653: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-07-04 21:39:28.820657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-07-04 21:39:28.820762: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-04 21:39:28.821008: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-04 21:39:28.821230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-04 21:39:28.821436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6820 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6)\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(64,(3,3), activation = tf.nn.relu, input_shape=(28,28,1)),\n",
    "    keras. layers.MaxPooling2D(2,2),\n",
    "    keras.layers.Conv2D(128,(3,3), activation = tf.nn.relu),\n",
    "    keras.layers.MaxPooling2D(2,2),\n",
    "    keras.layers.Conv2D(64,(3,3), activation = tf.nn.relu),\n",
    "    keras.layers.MaxPooling2D(2,2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation = tf.nn.relu),\n",
    "    keras.layers.Dense(units=10, activation = tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-04 21:39:29.163067: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-07-04 21:39:29.164276: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3799900000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-04 21:39:29.458059: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-07-04 21:39:29.997270: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8201\n",
      "2021-07-04 21:39:30.874040: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-07-04 21:39:31.423657: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-07-04 21:39:31.451062: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 9s 3ms/step - loss: 0.5650\n",
      "Epoch 2/5000\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3767\n",
      "Epoch 3/5000\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3189\n",
      "Epoch 4/5000\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2811\n",
      "Epoch 5/5000\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2540\n",
      "Epoch 6/5000\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2325\n",
      "Epoch 7/5000\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2122\n",
      "Epoch 8/5000\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1931\n",
      "Epoch 9/5000\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1781\n",
      "Epoch 10/5000\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1641\n",
      "Epoch 11/5000\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.1504\n",
      "Epoch 12/5000\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1418\n",
      "Epoch 13/5000\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.1299\n",
      "Epoch 14/5000\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.1189\n",
      "Epoch 15/5000\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1140\n",
      "Epoch 16/5000\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.1076\n",
      "Epoch 17/5000\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1004\n",
      "Epoch 18/5000\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0941\n",
      "Epoch 19/5000\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.0909\n",
      "Epoch 20/5000\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.0839\n",
      "Epoch 21/5000\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0792\n",
      "Epoch 22/5000\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.0772\n",
      "Epoch 23/5000\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0738\n",
      "Epoch 24/5000\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0673\n",
      "Epoch 25/5000\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0695\n",
      "Epoch 26/5000\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0680\n",
      "Epoch 27/5000\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0615\n",
      "Epoch 28/5000\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0621\n",
      "Epoch 29/5000\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0560\n",
      "Epoch 30/5000\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0574\n",
      "Epoch 31/5000\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0547\n",
      "Epoch 32/5000\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0533\n",
      "Epoch 33/5000\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0527\n",
      "Epoch 34/5000\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0512\n",
      "Epoch 35/5000\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0493\n",
      "Epoch 36/5000\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0509\n",
      "Epoch 37/5000\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0474\n",
      "Epoch 38/5000\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0448\n",
      "Epoch 39/5000\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0450\n",
      "Epoch 40/5000\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0474\n",
      "Epoch 41/5000\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0435\n",
      "Epoch 42/5000\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0455\n",
      "Epoch 43/5000\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0458\n",
      "Epoch 44/5000\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0417\n",
      "Epoch 45/5000\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0368\n",
      "Epoch 46/5000\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0427\n",
      "Epoch 47/5000\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0394\n",
      "Epoch 48/5000\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0391\n",
      "Epoch 49/5000\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0418\n",
      "Epoch 50/5000\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0337\n",
      "Epoch 51/5000\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0389\n",
      "Epoch 52/5000\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0401\n",
      "Epoch 53/5000\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0343\n",
      "Epoch 54/5000\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0373\n",
      "Epoch 55/5000\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0343\n",
      "Epoch 56/5000\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0387\n",
      "Epoch 57/5000\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0355\n",
      "Epoch 58/5000\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0358\n",
      "Epoch 59/5000\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0317\n",
      "Epoch 60/5000\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0321\n",
      "Epoch 61/5000\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0277\n",
      "Epoch 62/5000\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0345\n",
      "Epoch 63/5000\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0334\n",
      "Epoch 64/5000\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0349\n",
      "Epoch 65/5000\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0284\n",
      "Epoch 66/5000\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0318\n",
      "Epoch 67/5000\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0353\n",
      "Epoch 68/5000\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0296\n",
      "Epoch 69/5000\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0274\n",
      "Epoch 70/5000\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0371\n",
      "Epoch 71/5000\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0278\n",
      "Epoch 72/5000\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0320\n",
      "Epoch 73/5000\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0314\n",
      "Epoch 74/5000\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0303\n",
      "Epoch 75/5000\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0312\n",
      "Epoch 76/5000\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0300\n",
      "Epoch 77/5000\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0255\n",
      "Epoch 78/5000\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0304\n",
      "Epoch 79/5000\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0278\n",
      "Epoch 80/5000\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0307\n",
      "Epoch 81/5000\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0284\n",
      "Epoch 82/5000\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0323\n",
      "Epoch 83/5000\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0234\n",
      "Epoch 84/5000\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0323\n",
      "Epoch 85/5000\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0277\n",
      "Epoch 86/5000\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0284\n",
      "Epoch 87/5000\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0286\n",
      "Epoch 88/5000\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0275\n",
      "Epoch 89/5000\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0223\n",
      "Epoch 90/5000\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.0295\n",
      "Epoch 91/5000\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.0250\n",
      "Epoch 92/5000\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0301\n",
      "Epoch 93/5000\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0249\n",
      "Epoch 94/5000\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0281\n",
      "Epoch 95/5000\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0241\n",
      "Epoch 96/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0246\n",
      "Epoch 97/5000\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0279\n",
      "Epoch 98/5000\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0265\n",
      "Epoch 99/5000\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0252\n",
      "Epoch 100/5000\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0284\n",
      "Epoch 101/5000\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0255\n",
      "Epoch 102/5000\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0287\n",
      "Epoch 103/5000\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0254\n",
      "Epoch 104/5000\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0227\n",
      "Epoch 105/5000\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0261\n",
      "Epoch 106/5000\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0238\n",
      "Epoch 107/5000\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0232\n",
      "Epoch 108/5000\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0240\n",
      "Epoch 109/5000\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0256\n",
      "Epoch 110/5000\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0281\n",
      "Epoch 111/5000\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0249\n",
      "Epoch 112/5000\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0270\n",
      "Epoch 113/5000\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0180\n",
      "Epoch 114/5000\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0219\n",
      "Epoch 115/5000\n",
      " 681/1875 [=========>....................] - ETA: 5s - loss: 0.0367"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3319/837867329.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcustomCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "model.fit(training_images, training_labels, epochs=5000, callbacks=[customCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
